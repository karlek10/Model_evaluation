{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = sns.barplot(x=data[\"Class\"].unique(),y=data[\"Class\"].value_counts(),data=data, log = True)\n",
    "for b in bars.patches:\n",
    "    bars.annotate(int(b.get_height()), \n",
    "                   (b.get_x() + b.get_width() / 2., b.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 10), \n",
    "                   size = 14,\n",
    "                   textcoords = 'offset points')\n",
    "plt.xlabel(\"Validity of transaction\")\n",
    "plt.ylabel(\"Number of transactions\")\n",
    "plt.xticks(range(2),labels = [\"Valid\", \"Fraud\"], rotation = 0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:-2].values\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create and train the model\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Calculate the test set predictions\n",
    "log_predictions = logreg.predict(X_test)\n",
    "\n",
    "# Checks the test set predictions for unique values\n",
    "np.unique(log_predictions, return_counts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from sk-learn on Training data: 99.92%\n",
      "Accuracy from sk-learn on Test data: 99.93%\n"
     ]
    }
   ],
   "source": [
    "# Check the regression parameters, training and test precision\n",
    "# Training nad test set model accuracy\n",
    "print ('Accuracy from sk-learn on Training data: {0:.2f}%'.format(logreg.score(X_train, y_train)*100))\n",
    "print ('Accuracy from sk-learn on Test data: {0:.2f}%'.format(logreg.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create and train the Dummy model\n",
    "dummy_major = DummyClassifier(strategy = \"most_frequent\").fit(X_train, y_train)\n",
    "\n",
    "# Calculate the test set Dummy predictions\n",
    "dummy_major_predictions = dummy_major.predict(X_test)\n",
    "\n",
    "# Checks the Dummy predictions for unique values\n",
    "np.unique(dummy_major_predictions, return_counts=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from most frequent DummyClassifier on Training data: 99.83%\n",
      "Accuracy from most frequent DummyClassifier on Test data: 99.83%\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy from most frequent DummyClassifier on Training data: {0:.2f}%'.format(dummy_major.score(X_train, y_train)*100))\n",
    "print ('Accuracy from most frequent DummyClassifier on Test data: {0:.2f}%'.format(dummy_major.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71072,    10],\n",
       "       [   40,    80]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix for Logistic Regression model\n",
    "conf_matrix_log = confusion_matrix(y_test, log_predictions)\n",
    "\n",
    "conf_matrix_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71082,     0],\n",
       "       [  120,     0]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix for the Dummy Classifier\n",
    "conf_matrix_dummy = confusion_matrix(y_test, dummy_major_predictions)\n",
    "\n",
    "conf_matrix_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - Logistic Regression: 0.9993\n",
      "Accuracy - Dummy Classifier: 0.9983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print ('Accuracy - Logistic Regression: {0:.4f}'.format(accuracy_score(y_test, log_predictions)))\n",
    "print ('Accuracy - Dummy Classifier: {0:.4f}'.format(accuracy_score(y_test, dummy_major_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error - Logistic Regression: 0.0007\n",
      "Classification Error - Dummy Classifier: 0.0017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print ('Classification Error - Logistic Regression: {0:.4f}'.format((1-accuracy_score(y_test, log_predictions))))\n",
    "print ('Classification Error - Dummy Classifier: {0:.4f}'.format((1-accuracy_score(y_test, dummy_major_predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall - Logistic Regression: 0.6667\n",
      "Recall - Dummy Classifier: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print ('Recall - Logistic Regression: {0:.4f}'.format(recall_score(y_test, log_predictions)))\n",
    "print ('Recall - Dummy Classifier: {0:.4f}'.format(recall_score(y_test, dummy_major_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - Logistic Regression: 0.8889\n",
      "Precision - Dummy Classifier: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karlo\\anaconda3\\envs\\ml_courses\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print ('Precision - Logistic Regression: {0:.4f}'.format(precision_score(y_test, log_predictions)))\n",
    "print ('Precision - Dummy Classifier: {0:.4f}'.format(precision_score(y_test, dummy_major_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR - Logistic Regression: 0.00014\n",
      "FPR - Dummy: 0.00000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix for Logistic Regression model\n",
    "conf_matrix_log = confusion_matrix(y_test, log_predictions)\n",
    "\n",
    "FPR_logreg = conf_matrix_log[0][1] / (conf_matrix_log[0][0] + conf_matrix_log[0][1])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix for the Dummy Classifier\n",
    "conf_matrix_dummy = confusion_matrix(y_test, dummy_major_predictions)\n",
    "\n",
    "FPR_dummy = conf_matrix_dummy[0][1] / (conf_matrix_dummy[0][0] + conf_matrix_dummy[0][1])\n",
    "\n",
    "print ('FPR - Logistic Regression: {0:.5f}'.format(FPR_logreg))\n",
    "print ('FPR - Dummy: {0:.5f}'.format(FPR_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score - Logistic Regression: 0.7619\n",
      "F1_score - Dummy Classifier: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print ('F1-score - Logistic Regression: {0:.4f}'.format(f1_score(y_test, log_predictions)))\n",
    "print ('F1_score - Dummy Classifier: {0:.4f}'.format(f1_score(y_test, dummy_major_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLassification report - Logistic Regression\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       VALID       1.00      1.00      1.00     71082\n",
      "       FRAUD       0.89      0.67      0.76       120\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.94      0.83      0.88     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "CLassification report - Dummy Classifier\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Dummy - VALID       1.00      1.00      1.00     71082\n",
      "Dummy - FRAUD       0.00      0.00      0.00       120\n",
      "\n",
      "     accuracy                           1.00     71202\n",
      "    macro avg       0.50      0.50      0.50     71202\n",
      " weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karlo\\anaconda3\\envs\\ml_courses\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (\"CLassification report - Logistic Regression\\n\", \n",
    "       classification_report(y_test, log_predictions, target_names = [\"VALID\", \"FRAUD\"]))\n",
    "print (\"CLassification report - Dummy Classifier\\n\", \n",
    "       classification_report(y_test, dummy_major_predictions, target_names = [\"Dummy - VALID\", \"Dummy - FRAUD\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
